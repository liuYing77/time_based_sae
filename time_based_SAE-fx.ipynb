{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from simulator import AELayer, spk_t\n",
    "\n",
    "def my_stdp(ref_time, run_time, curr_time, spike_to_value,\n",
    "            t_minus, t_plus, weights, min_w, max_w, learn_rate,\n",
    "            last_pre_spikes, pre_spikes, \n",
    "            post_spikes, target_spikes):\n",
    "    w = weights\n",
    "    # time weight <==> sooner spikes (t->ref) should be more important    \n",
    "    tw = spike_to_value(ref_time, run_time, curr_time, 1.)\n",
    "\n",
    "#     # weight updates\n",
    "#     left_bound = max(t-tau_stdp+1-delay, 0)\n",
    "    if (post_spikes>0).any() or (target_spikes>0).any():\n",
    "#         print(\"post_spikes\")\n",
    "#         print(post_spikes)\n",
    "#         print(\"target_spikes\")\n",
    "#         print(target_spikes)\n",
    "        rows = np.where( np.logical_and(last_pre_spikes > (curr_time - t_minus), last_pre_spikes >= 0) )[0]\n",
    "#         print(\"ROWS\")\n",
    "#         print(rows)\n",
    "        if len(rows):\n",
    "            w[rows, :] += learn_rate*np.outer(last_pre_spikes[rows,0], target_spikes[:, 0])*tw\n",
    "            w[rows, :] -= learn_rate*np.outer(last_pre_spikes[rows,0], post_spikes[:, 0])*tw\n",
    "        \n",
    "        cols = np.where( target_spikes > 0 )[0]\n",
    "#         print(\"np.outer\")\n",
    "#         print(np.outer(np.ones_like(pre_spikes, dtype=spk_t), target_spikes[cols, 0]))\n",
    "#         print(\"w column\")\n",
    "#         print(w[:, 0])\n",
    "#         print(\"pre mult\")\n",
    "#         print(np.ones_like(pre_spikes, dtype=spk_t))\n",
    "#         print(\"target cols\")\n",
    "#         print(target_spikes[cols, 0])\n",
    "        w[:, cols] += (learn_rate*tw)*np.outer(np.ones_like(pre_spikes, dtype=spk_t), target_spikes[cols, 0])\n",
    "        cols = np.where( post_spikes > 0 )[0]\n",
    "        w[:, cols] -= (learn_rate*tw)*np.outer(np.ones_like(pre_spikes, dtype=spk_t), post_spikes[cols, 0])\n",
    "\n",
    "        w[w>max_w] = max_w\n",
    "        w[w<min_w] = min_w\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "# www = np.arange(3*2).reshape((3, 2))\n",
    "# www.T[1, :] = 333\n",
    "# print(www)\n",
    "# #network configuraiton\n",
    "# v_size = 21\n",
    "# h_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mnist_utils as mu\n",
    "train_x, train_y = mu.get_train_data()\n",
    "train_x /= 255. # <- wouldn't this make it [0., 1.]?\n",
    "v_size = 794\n",
    "h_size = 500\n",
    "run_time = 30\n",
    "description = {'level': 0,\n",
    "               'run_time': run_time,\n",
    "               'sizes': {'in': 4, 'hid': 5, 'rcn': 4},\n",
    "               'delays': {'in': np.ones(4),\n",
    "                          'hid': np.ones(5),\n",
    "                          'rcn': np.ones(4)},\n",
    "               'in_times': [[1.], [], [2.], []],\n",
    "               'neuron_params': {'v_thresh': 1.,   # membrane potential threshold\n",
    "                                 'v_rest':   0.,     # resting potential\n",
    "                                 'tau_m':    20.,},\n",
    "               'stdp': {'func':       my_stdp,\n",
    "                        'max_w':      0.5,\n",
    "                        'min_w':     -0.5,\n",
    "                        't_plus':     20.,\n",
    "                        't_minus':    20.,\n",
    "                        'learn_rate': 0.001,\n",
    "                        'target_times': [[5.], [], [7.], []]},\n",
    "              }\n",
    "\n",
    "lvl_0 = AELayer(description)\n",
    "prev_w  = lvl_0._w.copy()\n",
    "out_spk = None\n",
    "for i in range(run_time):\n",
    "    if i == 0:\n",
    "        out_spk = lvl_0.sim(i)\n",
    "    else:\n",
    "        out_spk[:] = lvl_0.sim(i)\n",
    "#     print(np.sum(lvl_0._w - prev_w))\n",
    "    prev_w[:] = lvl_0._w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weights initialization\n",
    "w_bound = 0.5 #0.3\n",
    "w_init = 0.1 #0.1\n",
    "# w = np.random.uniform(-w_init, w_init, (v_size, h_size)) \n",
    "w_offset = 0.05\n",
    "w = np.random.normal(w_offset, w_init, (v_size, h_size)) \n",
    "\n",
    "#LIF neuron parameters\n",
    "v_thresh = 1.   # membrane potential threshold\n",
    "v_rest = 0.     # resting potential\n",
    "tau_m = 20.     # membrane constant\n",
    "delay = 5       # synaptic delay\n",
    "\n",
    "#STDP config\n",
    "tau_stdp = 20   # STDP window length\n",
    "eta = 0.001  # learning rate\n",
    "delta_w = eta*np.logspace(0,1,tau_stdp)  #expenential decaying STDP curve\n",
    "\n",
    "\n",
    "\n",
    "run_len = 50      # Length of each trial\n",
    "teach_delay = 10  # Delay length of the teaching signal\n",
    "K = 30.\n",
    "record_flag = True #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Setting up the patterns to learn\n",
    "# patterns = list()\n",
    "# # # patterns.append([3,3,3,3,5,5,5,5,8,8,3,3,3,3,5,5,5,5,8,8])\n",
    "# # # patterns.append([2,2,2,2,2,8,8,8,8,8,2,2,2,2,2,8,8,8,8,8])\n",
    "# patterns.append([2,2,2,2,2,2,2,2,2,2,2,2,2,2,16,16,16,16,16,16,16]) #1,1,0 #16,16,16,16,16,16,16   #8,8,8,8,8,8,8\n",
    "# patterns.append([2,2,2,2,2,2,2,16,16,16,16,16,16,16,2,2,2,2,2,2,2]) #1,0,1\n",
    "# patterns.append([16,16,16,16,16,16,16,2,2,2,2,2,2,2,2,2,2,2,2,2,2]) #0,1,1\n",
    "\n",
    "# patterns = np.array(patterns)\n",
    "# print patterns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_test = 10\n",
    "patterns = np.int16(np.floor((1.-train_x[:num_test])*K ))\n",
    "patterns_y = np.zeros((num_test, 10))\n",
    "patterns_y[range(num_test), np.int16(train_y[:num_test])] = 1.\n",
    "patterns_y = np.int16(np.floor((1.-patterns_y[:num_test])*K ))\n",
    "patterns = np.append(patterns,patterns_y, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = 5 # training epochs\n",
    "\n",
    "# Recording of the neural status\n",
    "if record_flag:\n",
    "#     h_mem_list = []     # membrane potential of hiden units \n",
    "#     h_spike_list = []   # spikes of hiden units \n",
    "#     o_mem_list = []     # membrane potential of output units \n",
    "#     o_spike_list = []   # spikes of output units \n",
    "    w_list = []         # weights\n",
    "    loss_list = []\n",
    "    predict_list = []\n",
    "\n",
    "# Initialise neural status\n",
    "h_spike = np.zeros((h_size, run_len))   # no output spikes from hiden units \n",
    "o_spike = np.zeros((v_size, run_len))   # no output spikes from ouput units \n",
    "h_mem = np.zeros((h_size, 1))           # membrane potential=0 mV for hiden units \n",
    "o_mem = np.zeros((v_size, 1))           # membrane potential=0 mV for output units \n",
    "\n",
    "for iteration in range(epoch):\n",
    "    print 'epoch:%d'%iteration\n",
    "    for p_id in range(patterns.shape[0]):\n",
    "        # reset the neural status\n",
    "        h_mem[:] = v_rest\n",
    "        o_mem[:] = v_rest\n",
    "        h_spike[:,:] = v_rest\n",
    "        o_spike[:,:] = v_rest\n",
    "        \n",
    "        # the input spikes and the teaching signal\n",
    "        v_spike = np.zeros((v_size, run_len))\n",
    "        v_teach = np.zeros((v_size, run_len))\n",
    "        \n",
    "        v_pattern = np.copy(patterns[p_id,:])\n",
    "        \n",
    "        # add noise to the input signal\n",
    "#         v_pattern += np.random.normal(0, 0.1, v_pattern.shape)\n",
    "#         v_pattern[v_pattern<0] = 0\n",
    "        \n",
    "        v_spike[(range(v_size), v_pattern)]=1.\n",
    "        v_spike[:, K]=0.\n",
    "        v_teach[(range(v_size), np.array(v_pattern)+teach_delay)] = 1.\n",
    "        \n",
    "        # in the period of delay, nothing changed\n",
    "#         if record_flag:\n",
    "#             for t in range(delay):\n",
    "#                 h_mem_list.append(h_mem.copy())\n",
    "#                 h_spike_list.append(h_spike[:, t].copy())\n",
    "#                 o_mem_list.append(o_mem.copy())\n",
    "#                 o_spike_list.append(o_spike[:, t].copy())\n",
    "#                 w_list.append(w.flatten())\n",
    "            \n",
    "        # Main part for neural status updating\n",
    "        for t in range(delay,run_len):\n",
    "            # hid units\n",
    "            h_mem *= np.exp(-1/tau_m)   #decay\n",
    "            h_mem += np.reshape(np.dot(v_spike[:,t-delay],w),(h_mem.shape))  # add up spiking input\n",
    "            h_spike[(h_mem>v_thresh)[:,0], t] = 1.  #generate spikes\n",
    "            h_mem[(h_mem>v_thresh)] = v_rest        #reset membrane potential\n",
    "            #h_mem[(h_mem<v_rest)] = v_rest\n",
    "\n",
    "            \n",
    "            # output units\n",
    "            o_mem *= np.exp(-1/tau_m)\n",
    "            o_mem += np.reshape(np.dot(h_spike[:,t-delay],np.transpose(w)),(o_mem.shape))\n",
    "            o_spike[(o_mem>v_thresh)[:,0], t] = 1.\n",
    "            o_mem[(o_mem>v_thresh)] = v_rest\n",
    "            #o_mem[(o_mem<v_rest)] = v_rest\n",
    "\n",
    "\n",
    "            # t indicates the importance\n",
    "            impt = np.float(run_len-t+delay)/np.float(run_len)\n",
    "            \n",
    "            # weight updates\n",
    "            left_bound = max(t-tau_stdp+1-delay, 0)\n",
    "            if (o_spike[:, t]>0).any() or (v_teach[:, t]>0).any():\n",
    "                \n",
    "                # Look the spikes of hiden units for a time period of STDP window\n",
    "                temp_deltaw = np.einsum('jk,k->jk', h_spike[:, left_bound:t-delay+1], delta_w[left_bound-t+delay-1:])\n",
    "\n",
    "            # W-\n",
    "                w -= np.sum(np.einsum('i,jk->ijk', o_spike[:, t], temp_deltaw), axis=2)*impt #STDP\n",
    "                w[o_spike[:, t]>0, :] -= (eta*impt*0.1) # weights decrease even without STDP\n",
    "            # W+\n",
    "                w += np.sum(np.einsum('i,jk->ijk', v_teach[:, t], temp_deltaw), axis=2)*impt #STDP\n",
    "                w[v_teach[:, t]>0, :] += (eta*impt*0.1) # weights increase even without STDP\n",
    "\n",
    "                w[w>w_bound] = w_bound\n",
    "                w[w<-w_bound] = -w_bound\n",
    "            \n",
    "#             if record_flag:\n",
    "#                 h_mem_list.append(h_mem.copy())\n",
    "#                 h_spike_list.append(h_spike[:, t].copy())\n",
    "#                 o_mem_list.append(o_mem.copy())\n",
    "#                 o_spike_list.append(o_spike[:, t].copy())\n",
    "#                 w_list.append(w.flatten())\n",
    "        if np.mod(p_id,1)==0: #p_id == patterns.shape[0]-1:# and  np.mod(iteration,10) == 9: \n",
    "#             print iteration\n",
    "#             neuron_id, time_stamp = np.where(o_spike==1)\n",
    "#             plt.plot(time_stamp, neuron_id, '.')\n",
    "#             plt.xlim((0,run_len))\n",
    "#             plt.show()\n",
    "            \n",
    "            recon = (o_spike.argmax(axis=1)-teach_delay)*1.\n",
    "            \n",
    "            recon[recon>=0] = (K-recon[recon>=0])/K\n",
    "            recon[recon<0] = 0\n",
    "            \n",
    "            loss =  ((((K-patterns)/K)[p_id]-recon.flatten()) ** 2).mean()\n",
    "#             print 'Loss:', ((((K-patterns)/K)[p_id]-recon.flatten()) ** 2).mean()\n",
    "            \n",
    "            predict = np.argmax(recon[-10:]) \n",
    "\n",
    "#             print 'Predict: ', np.argmax(predict) \n",
    "#             print predict\n",
    "#             recon_img = np.reshape(recon[:-10], (28,28))\n",
    "#             plt.imshow(recon_img, cmap=cm.gray_r, clim=(0,1))\n",
    "#             plt.show()\n",
    "            if record_flag:\n",
    "                loss_list.append(loss)\n",
    "#                 predict_list.append(predict)\n",
    "#                 w_list.append(w.flatten())\n",
    "                w_list.append(w[-10:,:].flatten())\n",
    "                print p_id, '%0.3f'%loss, np.int16(train_y[p_id]), predict, '%.2f'%recon[-10+predict]\n",
    "    if np.mod(iteration,10) == 9:\n",
    "        delta_w *= 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(loss_list)\n",
    "avg_num = 10\n",
    "img_num = len(loss_list)\n",
    "loss_plot = np.reshape(np.array(loss_list), (img_num/avg_num, avg_num))\n",
    "plt.semilogy(np.average(loss_plot,axis=1))\n",
    "plt.title('Loss (MSE)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_list = np.array(w_list)\n",
    "plt.plot(w_list[:,::10])\n",
    "print w_list.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
